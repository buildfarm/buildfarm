syntax = "proto3";

package build.buildfarm.v1test;

import "google/api/annotations.proto";
import "build/bazel/remote/execution/v2/remote_execution.proto";
import "google/longrunning/operations.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";
import "google/rpc/status.proto";

option go_package = "buildfarm";
option java_package = "build.buildfarm.v1test";
option java_multiple_files = true;
option java_outer_classname = "OperationQueueProto";

// The Admin API is used to perform administrative functions on Buildfarm infrastructure
service Admin {
  rpc TerminateHost(TerminateHostRequest) returns (google.rpc.Status) {
    option (google.api.http) = { get: "/v1test/admin:terminateHost" };
  }

  rpc StopContainer(StopContainerRequest) returns (google.rpc.Status) {
    option (google.api.http) = { get: "/v1test/admin:stopContainer" };
  }

  rpc GetHosts(GetHostsRequest) returns (GetHostsResult) {
    option (google.api.http) = { get: "/v1test/admin:getHosts" };
  }

  rpc GetClientStartTime(GetClientStartTimeRequest) returns (GetClientStartTimeResult) {
    option (google.api.http) = { get: "/v1test/admin:getClientStartTime" };
  }

  rpc ScaleCluster(ScaleClusterRequest) returns (google.rpc.Status) {
    option (google.api.http) = { get: "/v1test/admin:scaleCluster" };
  }

  rpc ReindexCas(ReindexCasRequest) returns (ReindexCasRequestResults) {
    option (google.api.http) = { get: "/v1test/admin:reindexCas" };
  }
  rpc ReindexAllCas(ReindexAllCasRequest) returns (ReindexCasRequestResults) {
    option (google.api.http) = { get: "/v1test/admin:reindexAllCas" };
  }
  
  rpc ShutDownWorkerGracefully(ShutDownWorkerGracefullyRequest) returns (ShutDownWorkerGracefullyRequestResults) {
    option (google.api.http) = { get: "/v1test/admin:deregisterWorker" };
  }

  rpc DisableScaleInProtection(DisableScaleInProtectionRequest) returns (DisableScaleInProtectionRequestResults) {
    option (google.api.http) = { get: "/v1test/admin:disableScaleInProtection" };
  }
}

message ShutDownWorkerGracefullyRequest{
  string instance_name = 1;
  
  string worker_name = 2;
}

message ShutDownWorkerGracefullyRequestResults {
}

message DisableScaleInProtectionRequest{
  string instance_name = 1;
}

message DisableScaleInProtectionRequestResults{
}

message ReindexCasRequest {
  string instance_name = 1;

  // format: ip:port
  string host_id = 2;
  }

message ReindexAllCasRequest {
  string instance_name = 1;
}

message ReindexCasRequestResults {
  int32 removedHosts = 1;

  int32 removedKeys = 2;

  int32 totalKeys = 3;
}

message TerminateHostRequest {
  string instance_name = 1;

  string host_id = 2;
}

message StopContainerRequest {
  string instance_name = 1;

  string host_id = 2;

  string container_name = 3;
}

message GetHostsRequest {
  string filter = 1;

  int32 age_in_minutes = 2;

  string status = 3;
}

message GetHostsResult {
  int64 num_hosts = 1;

  repeated Host hosts = 2;
}

message Host {
  int64 host_num = 1;

  string host_id = 2;

  string ip_address = 3;

  google.protobuf.Timestamp launch_time = 4;

  string state = 5;

  string dns_name = 6;

  int64 uptime_minutes = 7;

  int64 num_cores = 8;

  string type = 9;

  string lifecycle = 10;
}

message GetClientStartTimeRequest {
  string instance_name = 1;
  repeated string host_name = 2;
}

message GetClientStartTimeResult {
  repeated GetClientStartTime client_start_time = 1;
}

message GetClientStartTime {
  string instance_name = 1;
  google.protobuf.Timestamp client_start_time = 2;
}

message ScaleClusterRequest {
  string scale_group_name = 1;

  int32 min_hosts = 2;

  int32 max_hosts = 3;

  int32 target_hosts = 4;

  int32 target_reserved_hosts_percent = 5;
}

// The OperationQueue API is used internally to communicate with Workers
service OperationQueue {
  rpc Take(TakeOperationRequest) returns (QueueEntry) {
    option (google.api.http) = { get: "/v1test/{instance_name=**}/operation:take" };
  }

  rpc Put(google.longrunning.Operation) returns (google.rpc.Status) {
    option (google.api.http) = { post: "/v1test/{instance_name=**}/operation:put" body: "*" };
  }

  rpc Poll(PollOperationRequest) returns (google.rpc.Status) {
    option (google.api.http) = { get: "/v1test/{instance_name=**}/operation:poll" };
  }

  rpc Status(BackplaneStatusRequest) returns (BackplaneStatus) {
    option (google.api.http) = { get: "/v1test/{instance_name=**}/operation:status" };
  }
}

message BackplaneStatusRequest {
  string instance_name = 1;
}

message TakeOperationRequest {
  // The instance of the execution system to operate against. A server may
  // support multiple instances of the execution system (with their own workers,
  // storage, caches, etc.). The server MAY require use of this field to select
  // between them in an implementation-defined fashion, otherwise it can be
  // omitted.
  string instance_name = 1;

  // The platform features available for the execution environment. The server MAY
  // choose to execute the action on any worker satisfying the requirements, so
  // the client SHOULD ensure that running the action on any such worker will
  // have the same result.
  build.bazel.remote.execution.v2.Platform platform = 5;
}

message PollOperationRequest {
  // The operation name in question
  string operation_name = 2;

  // The current state of the worker
  build.bazel.remote.execution.v2.ExecutionStage.Value stage = 3;
}

message BuildFarmServerConfig {
  InstanceConfig instance = 1;

  int32 port = 2;

  int32 execute_keepalive_after_seconds = 3;

  MetricsConfig metrics_config = 4;

  AdminConfig admin_config = 5;

  PrometheusConfig prometheus_config = 6;
  
  BuildEventConfig build_event_config = 7;
  
  // Absolute path to the PEM file containing both the required certificates and any
  // associated private key.
  optional string ssl_certificate_path = 8;

  // CAS write deadline
  google.protobuf.Duration cas_write_timeout = 9;

  // Bytestream upload blob deadline
  google.protobuf.Duration bytestream_timeout = 10;
}

message MetricsConfig {
  string metrics_destination = 1;

  string cluster_id = 2;

  oneof type {
    AwsMetricsConfig aws_metrics_config = 3;
    GcpMetricsConfig gcp_metrics_config = 4;
    LogMetricsConfig log_metrics_config = 5;
  }
}

message AwsMetricsConfig {
  string operations_metrics_topic = 1;

  int32 sns_client_max_connections = 2;

  string secret_name = 3;

  string region = 4;
}

message GcpMetricsConfig {
  string operations_metrics_topic = 1;
}

message LogMetricsConfig {
  string log_level = 1;
}

message PrometheusConfig {
  int32 port = 1;
}

message BuildEventConfig {
  bool record_events = 1;
}

message AdminConfig {
  string deployment_environment = 1;

  string cluster_id = 4;

  string cluster_endpoint = 6;

  oneof type {
    AwsAdminConfig aws_admin_config = 2;
    GcpAdminConfig gcp_admin_config = 3;
  }

  bool enable_graceful_shutdown = 5;
}

message AwsAdminConfig {
  string region = 1;
}

message GcpAdminConfig {
}

message MemoryCASConfig {
  // limit for CAS total content size
  int64 max_size_bytes = 1;
}

message GrpcCASConfig {
  // CAS resources must contain instance names
  string instance_name = 1;

  // grpc endpoint supporting CAS/BS
  string target = 2;
}

message FilesystemCASConfig {
  // path to cached files from CAS
  // if relative, is made relative to root
  string path = 1;

  // limit for contents of files retained
  // from CAS in the cache
  int64 max_size_bytes = 2;

  // limit for contents of a single file retained
  // from CAS in the cache
  int64 max_entry_size_bytes = 3;

  // exponential levels of blob bucketing by digest
  // if digest is afcd0123, with 2 here, it will live in af/cd/af0123
  // 0 (default) here will put all entries at the cache root
  int32 hex_bucket_levels = 5;

  // whether the file directories bidirectional mapping should be stored in memory (HashMap) or
  // in sqlite
  bool file_directories_index_in_memory = 4;
}

message FilesystemACConfig {
  // path to action cache files from AC
  string path = 1;
}

message FuseCASConfig {
  // used to identify the backing store
  string name = 1;
}

message ContentAddressableStorageConfig {
  oneof type {
    MemoryCASConfig memory = 1;
    GrpcCASConfig grpc = 2;
    FilesystemCASConfig filesystem = 3;
    FuseCASConfig fuse = 4;
  }
  
  // whether the transient data on the worker should be loaded into the CAS on worker startup
  bool skip_load = 5;
}

message DelegateCASConfig {
}

message GrpcACConfig {
  // AC requests can contain instance names
  string instance_name = 1;

  // grpc endpoint supporting AC
  string target = 2;
}

message ActionCacheConfig {
  oneof type {
    DelegateCASConfig delegate_cas = 1;
    FilesystemACConfig filesystem = 3;
    GrpcACConfig grpc = 2;
  }
}

message MemoryInstanceConfig {
  // the limits of the listOperations request
  int32 list_operations_default_page_size = 1;
  int32 list_operations_max_page_size = 2;

  // the limits of the getTree request
  int32 tree_default_page_size = 3;
  int32 tree_max_page_size = 4;

  // timeout after dispatch before which executing,
  // complete or an operation poll must be received, or
  // the operation is considered lost on a worker and is
  // requeued
  google.protobuf.Duration operation_poll_timeout = 5;

  // delay after timeout when executing before which
  // completed must be received, or the operation is
  // considered lost on a worker and is requeued
  google.protobuf.Duration operation_completed_delay = 6;

  // default timeout for actions
  // if a timeout is unspecified for an action, this value
  // is imposed on it, after which the operation will be
  // cancelled
  google.protobuf.Duration default_action_timeout = 7;

  // maximum selectable timeout
  // a maximum threshold for an action's specified timeout,
  // beyond which an action will be rejected for execution
  google.protobuf.Duration maximum_action_timeout = 8;

  ContentAddressableStorageConfig cas_config = 9;

  ActionCacheConfig action_cache_config = 10;
}

message ProvisionedQueue {
  string name = 1;
  
  bool allow_unmatched = 3;
  
  build.bazel.remote.execution.v2.Platform platform = 2;
}

message ProvisionedQueuesConfig {
  repeated ProvisionedQueue queues = 1;
}

message RedisShardBackplaneConfig {
  // the uri endpoint of the redis target. This must be a single host entry
  // with cluster discoverability enabled if the redis service is configured
  // for cluster operation. If the endpoint is a singleton redis node, cluster
  // adaptive behaviors, specifically queue balancing, will be emulated.
  string redis_uri = 1;

  // the password used to authenticate to redis via `auth`
  string redis_password = 34;

  // the size of the pool of jedis connections per-cluster-member
  int32 jedis_pool_max_total = 15;

  // the hash of active cas shards. Shards must update a self-reported expiry
  // regularly or face deactivation and excommunication. Advertisements for
  // contents on deactivated workers may be pruned.
  string workers_hash_name = 2;

  // the channel used to communicate cas shard structural changes
  string worker_channel = 25;

  // the prefix of keys which map action keys to action results
  string action_cache_prefix = 3;

  // the expiration time in seconds for action cache entries
  int32 action_cache_expire = 4;

  // the prefix of keys which identify actions that are to be rejected
  // from any request endpoint
  string action_blacklist_prefix = 28;

  // the expiration time in seconds for banned actions
  int32 action_blacklist_expire = 29;

  // the prefix of keys which identify invocations that are to be rejected
  // from any request endpoint
  string invocation_blacklist_prefix = 30;

  // the prefix of keys used to retain current Operation state
  string operation_prefix = 5;

  // the expiration time in seconds for operation keys
  int32 operation_expire = 6;

  // the arrival queue. Contains ExecuteEntry messages
  string pre_queued_operations_list_name = 18;

  // the atomic target list for reliable arrival queue removal
  string processing_list_name = 19;

  // the prefix of the processing list timeout monitor key
  string processing_prefix = 20;

  // the minimum timeout for an operation to be removed from the processing list
  // upon leaving the arrival queue
  int32 processing_timeout_millis = 21;

  // the ready-to-run operation queue. Contains QueueEntry messages
  string queued_operations_list_name = 7;

  // the prefix of the dispatching list timeout monitor key
  string dispatching_prefix = 23;

  // the minimum timeout for an operation to be observable in the dispatched
  // hash upon leaving the ready-to-run queue.
  int32 dispatching_timeout_millis = 24;

  // the hash key of dispatched operations. all operations which have been
  // removed from the ready-to-run queue should make their way here in a timely
  // (per dispatching) fashion.
  string dispatched_operations_hash_name = 8;

  // the prefix of operation update topics
  string operation_channel_prefix = 9;

  // the prefix of cas set keys. A cas set for a key suffixed with a digest
  // address, contain the shards which have advertised storage of the
  // addressed content. This set of valid shards for a digest must intersect
  // with the active shard list (workers)
  string cas_prefix = 10;

  // the expiration time in seconds for cas sets
  int32 cas_expire = 11;
  
  //whether or not to cache the cas set in memory
  bool cache_cas = 35;

  // whether to listen to the backplane communication streams for shard lifecycle
  // events and watched operations. This is required for failsafe operation below
  // and realtime notification for watched operations.
  // This is nearly required for schedulers, and may be useful elsewhere
  bool subscribe_to_backplane = 26;

  // whether to run the failsafe operation monitor, which establishes watchdogs
  // on watched operations, to ensure they are in a known or recently refreshed
  // state, and guaranteeing a watch's termination on expiry
  // This monitor also effects processing/dispatching expirations globally, required
  // to ensure queue reliability.
  // This is recommended for schedulers, meaningless for others
  bool run_failsafe_operation = 27;

  // the maximum size allowed for the ready-to-run queue before rejection
  int32 max_queue_depth = 16;

  // the maximum size allowed for the arrival queue before rejection
  int32 max_pre_queue_depth = 17;

  // the provisioned queue definitions for platform partitioning
  ProvisionedQueuesConfig provisioned_queues = 31;

  // connection and socket read timeout for jedis
  int32 timeout = 32;

  // maximum number of retries in a cluster
  int32 max_attempts = 33;
}

message ShardInstanceConfig {
  bool run_dispatched_monitor = 1;

  int32 dispatched_monitor_interval_seconds = 2;

  bool run_operation_queuer = 3;

  oneof backplane {
    RedisShardBackplaneConfig redis_shard_backplane_config = 4;
  }

  int64 max_entry_size_bytes = 5;
  
  int32 max_cpu = 9;

  // maximum selectable timeout
  // a maximum threshold for an action's specified timeout,
  // beyond which an action will be rejected for execution
  google.protobuf.Duration maximum_action_timeout = 7;
  
  // default timeouts on grpc requests made by instances
  google.protobuf.Duration grpc_timeout = 8;
  
  // Whether the instance should consult a denylist when looking up actions & invocations.
  bool use_deny_list = 10;

  int32 max_requeue_attempts = 11;
}

message ShardWorkerInstanceConfig {
  // whether to stream stdout from processes
  bool stream_stdout = 6;

  // control for process stdout
  CASInsertionPolicy stdout_cas_policy = 7;

  // whether to stream stderr from processes
  bool stream_stderr = 8;

  // control for process stdout
  CASInsertionPolicy stderr_cas_policy = 9;

  // control for process output files
  CASInsertionPolicy file_cas_policy = 10;

  // page size for getTree request
  uint32 tree_page_size = 12;
  
  // default timeouts on grpc requests made by instances
  google.protobuf.Duration grpc_timeout = 13;
}

message DequeueMatchSettings {
  
  // whether a worker should accept everything it gets off the queue.
  bool accept_everything = 1;

  // whether a worker should accept platform properties that it does not match with.
  bool allow_unmatched = 2;
  
  // worker platform used to match operations
  build.bazel.remote.execution.v2.Platform platform = 3;
}

message WorkerCapabilities {
  
  // This determines whether the shard instance will participate in the backplane
  // and cache it's operation outputs in its own cache file CAS.
  // When omitted from CAS, the worker will send its execution outputs.
  bool cas = 1;
  
  // This determines whether the shard instance will participate in the execution pool.
  // Workers that don't execute may be used for storage only.
  bool execution = 2;
}

message ShardWorkerConfig {
  ShardWorkerInstanceConfig shard_worker_instance_config = 1;

  int32 port = 2;

  string public_name = 3;

  // base directory for all work being performed
  string root = 4;

  // the sequence of cas into which expirations cascade
  repeated ContentAddressableStorageConfig cas = 27;

  // period of poll requests during execution
  google.protobuf.Duration operation_poll_period = 13;

  //settings used to match with operations
  DequeueMatchSettings dequeue_match_settings = 36;

  // total size of the inline content for
  // action results
  int32 inline_content_limit = 15;

  // input fetch width
  int32 input_fetch_stage_width = 26;

  // execute width
  int32 execute_stage_width = 16;

  // symlink cas input-only directories
  bool link_input_directories = 17;

  // selected hash function
  build.bazel.remote.execution.v2.DigestFunction.Value digest_function = 18;

  // default timeout for actions
  // if a timeout is unspecified for an action, this value
  // is imposed on it, after which the operation will
  // be killed
  google.protobuf.Duration default_action_timeout = 19;

  // maximum selectable timeout
  // a maximum threshold for an action's specified timeout,
  // beyond which an action will be rejected for execution
  google.protobuf.Duration maximum_action_timeout = 20;

  oneof backplane {
    RedisShardBackplaneConfig redis_shard_backplane_config = 21;
  }

  // available execution policies, will be used to match
  // with an action's platform for selection
  repeated ExecutionPolicy execution_policies = 25;

  // support any execution limiting, whether global or specified
  bool limit_execution = 31;

  // limit the available cores to execute_stage_width for unmetered execution if set
  bool limit_global_execution = 29;

  // only allow test executions to be multicore (min-cores > 1), limiting both to 1 if not a test
  bool only_multicore_tests = 30;

  // user principal name for executions
  string exec_owner = 32;
  
  WorkerCapabilities capabilities = 38;
  
  bool error_operation_remaining_resources = 34;

  AdminConfig admin_config = 35;

  PrometheusConfig prometheus_config = 37;

  // a limit on time (in seconds) for input fetch stage to fetch inputs
  int32 input_fetch_deadline = 39;
  
}

message ShardWorker {
  string endpoint = 1;

  int64 expire_at = 2;
}

message WorkerChange {
  message Add {
  }

  message Remove {
    string source = 1;

    string reason = 2;
  }

  string name = 1;

  google.protobuf.Timestamp effectiveAt = 2;

  oneof type {
    Add add = 3;

    Remove remove = 4;
  }
}

message OperationChange {
  message Reset {
    google.protobuf.Timestamp expiresAt = 1;

    google.longrunning.Operation operation = 2;
  }

  message Expire {
    bool force = 1;
  }

  google.protobuf.Timestamp effectiveAt = 1;

  string source = 2;

  oneof type {
    Reset reset = 3;

    Expire expire = 4;
  }
}

message DispatchedOperation {
  QueueEntry queue_entry = 1;

  int64 requeue_at = 2;
}

message ProfiledQueuedOperationMetadata {
  QueuedOperation queued_operation = 1;

  QueuedOperationMetadata queued_operation_metadata = 2;

  google.protobuf.Duration transformed_in = 3;

  google.protobuf.Duration validated_in = 4;

  google.protobuf.Duration uploaded_in = 5;
}

message ExecuteEntry {
  string operation_name = 1;

  build.bazel.remote.execution.v2.Digest action_digest = 2;

  bool skip_cache_lookup = 3;

  build.bazel.remote.execution.v2.RequestMetadata request_metadata = 4;

  build.bazel.remote.execution.v2.ExecutionPolicy execution_policy = 5;

  build.bazel.remote.execution.v2.ResultsCachePolicy results_cache_policy = 6;

  string stdout_stream_name = 7;

  string stderr_stream_name = 8;

  google.protobuf.Timestamp queued_timestamp = 9;
}

message QueueEntry {
  ExecuteEntry execute_entry = 1;

  build.bazel.remote.execution.v2.Digest queued_operation_digest = 2;

  build.bazel.remote.execution.v2.Platform platform = 3;

  int32 requeue_attempts = 4;
}

message QueueStatus {
  int64 size = 1;

  repeated int64 internal_sizes = 2;
  
  string name = 3;
}

message OperationQueueStatus {
  repeated QueueStatus provisions = 1;
  
  int64 size = 2;
}

message LabeledCount {
  string name = 1;
  
  int64 size = 2;
}

message DispatchedOperationsStatus {
  
  // the total number of currently dispatched operations
  int64 size = 1;
  
  // how many of the current dispatched operations are 'build' related
  int64 build_action_amount = 2;
  
  // how many of the current dispatched operations are 'test' related
  int64 test_action_amount = 3;
  
  // how many of the current dispatched operations cannot be fetched and determine the type
  int64 unknown_action_amount = 4;
  
  // count dispatched operations by the queue they originated in
  // for example, "how many cpu vs gpu operations are running?"
  repeated LabeledCount from_queues = 5;
  
  // count dispatched operations by the tool they originated from
  // for example, "Is anyone using a build tool or bazel version not supported by the main repo?"
  repeated LabeledCount tools = 6;
  
  // count the kinds of action mnemonics occurring.
  // for example, CppCompile or GoLink.
  repeated LabeledCount action_mnemonics = 7;

  // count the program names being run for the command
  // for example, clang, bash.
  repeated LabeledCount command_tools = 8;
  
  // count the unique targets being resolved
  repeated LabeledCount target_ids = 9;
  
  // count the unique configurations being used
  repeated LabeledCount config_ids = 10;
  
  // platform properties used by the dispatched operations
  repeated LabeledCount platform_properties = 11;
  
  // how many unique clients are currently being served.
  // This is based on the uniqueness of tool_id for currently dispatched operations.
  int64 unique_clients_amount = 12;
  
  // how many of the dispatched operations have been requeued.
  // many requeued operations could be a sign of a problem.
  int64 requeued_operations_amount = 13;
}

message BackplaneStatus {
  QueueStatus prequeue = 1;

  OperationQueueStatus operation_queue = 2;
  
  DispatchedOperationsStatus dispatched_operations = 9;

  repeated string active_workers = 4;
  
  int64 cas_lookup_size = 5;
  
  int64 action_cache_size = 6;
  
  int64 blocked_actions_size = 7;
  
  int64 blocked_invocations_size = 8;
  
  int64 fetch_time_ms = 10;

  int64 dispatched_size = 11;
}

message QueuedOperationMetadata {
  build.bazel.remote.execution.v2.ExecuteOperationMetadata execute_operation_metadata = 1;

  build.bazel.remote.execution.v2.Digest queued_operation_digest = 2;

  build.bazel.remote.execution.v2.RequestMetadata request_metadata = 3;
}

// A `Tree` contains all the
// [Directory][build.bazel.remote.execution.v2.Directory] protos in a
// single directory Merkle tree, compressed into one message, with a map
// to index the directories.
message Tree {
  // The digest of the root directory in the tree.
  build.bazel.remote.execution.v2.Digest rootDigest = 1;

  map<string, build.bazel.remote.execution.v2.Directory> directories = 2;
}

message QueuedOperation {
  build.bazel.remote.execution.v2.Action action = 1;

  build.bazel.remote.execution.v2.Command command = 2;

  build.bazel.remote.execution.v2.Tree legacy_tree = 4;

  Tree tree = 5;
}

message ExecutingOperationMetadata {
  build.bazel.remote.execution.v2.ExecuteOperationMetadata execute_operation_metadata = 1;

  build.bazel.remote.execution.v2.RequestMetadata request_metadata = 2;

  int64 started_at = 3;

  string executing_on = 4;
}

message CompletedOperationMetadata {
  build.bazel.remote.execution.v2.ExecuteOperationMetadata execute_operation_metadata = 1;

  build.bazel.remote.execution.v2.RequestMetadata request_metadata = 2;

  reserved 3 to 8; // fields now in ExecutedActionMetadata
}

message OperationRequestMetadata {
  string operation_name = 1;

  bool done = 2;

  build.bazel.remote.execution.v2.RequestMetadata request_metadata = 3;

  build.bazel.remote.execution.v2.ExecuteOperationMetadata execute_operation_metadata = 4;

  build.bazel.remote.execution.v2.ExecuteResponse execute_response = 5;

  string cluster_id = 6;
}

message InstanceConfig {
  string name = 1;

  build.bazel.remote.execution.v2.DigestFunction.Value digest_function = 2;

  oneof type {
    MemoryInstanceConfig memory_instance_config = 3;
    ShardInstanceConfig shard_instance_config = 4;
  }
}

enum CASInsertionPolicy {
  UNKNOWN = 0;

  ALWAYS_INSERT = 1;

  INSERT_ABOVE_LIMIT = 2;
};

message InstanceEndpoint {
  // target suitable for grpc channel creation: host:port is common
  string target = 1;

  // instance to be used
  string instance_name = 2;

  // deadline for requests in seconds
  int32 deadline_after_seconds = 3;
}

message ExecutionWrapper {
  string path = 1;

  repeated string arguments = 2;
}

// selectable controls for executions
// a universal policy can be specified with an empty name
message ExecutionPolicy {
  string name = 1;

  oneof policy {
    ExecutionWrapper wrapper = 2;
  }
}

message WorkerConfig {
  build.bazel.remote.execution.v2.DigestFunction.Value digest_function = 1;

  // endpoint for all cas requests
  InstanceEndpoint content_addressable_storage = 2;

  // endpoint for all action cache requests
  InstanceEndpoint action_cache = 3;

  // endpoint for all operation execution requests
  InstanceEndpoint operation_queue = 4;

  // base directory for all work being performed
  string root = 5;

  // path to cached files from CAS
  // if relative, is made relative to root
  string cas_cache_directory = 6;

  // limit for contents of files retained
  // from CAS in the cache
  int64 cas_cache_max_size_bytes = 7;

  // limit for contents of a single file retained
  // from CAS in the cache
  int64 cas_cache_max_entry_size_bytes = 24;

  // exponential levels of blob bucketing by digest
  // if digest is afcd0123, with 2 here, it will live in af/cd/af0123
  // 0 (default) here will put all entries at the cache root
  int32 cas_cache_hex_bucket_levels = 27;

  // whether the file directories bidirectional mapping should be stored in memory (HashMap) or
  // in sqlite
  bool cas_cache_file_directories_index_in_memory = 28;

  // total size of the inline content for
  // action results
  int32 inline_content_limit = 8;

  // whether to stream stdout from processes
  bool stream_stdout = 9;

  // policy for process stdout
  CASInsertionPolicy stdout_cas_policy = 10;

  // whether to stream stderr from processes
  bool stream_stderr = 11;

  // policy for process stdout
  CASInsertionPolicy stderr_cas_policy = 12;

  // policy for process output files
  CASInsertionPolicy file_cas_policy = 13;

  reserved 14;

  // page size for getTree request
  uint32 tree_page_size = 15;

  // period of poll requests during execution
  google.protobuf.Duration operation_poll_period = 16;

  // initial platform used to match operations
  build.bazel.remote.execution.v2.Platform platform = 17;

  // default platform to populate matched commands
  build.bazel.remote.execution.v2.Platform default_platform = 25;

  // input fetch width
  int32 input_fetch_stage_width = 23;

  // execute width
  int32 execute_stage_width = 18;

  // symlink cas input-only directories
  bool link_input_directories = 19;

  // default timeout for actions
  // if a timeout is unspecified for an action, this value
  // is imposed on it, after which the operation will
  // be killed
  google.protobuf.Duration default_action_timeout = 20;

  // maximum selectable timeout
  // a maximum threshold for an action's specified timeout,
  // beyond which an action will be rejected for execution
  google.protobuf.Duration maximum_action_timeout = 21;

  // available execution policies, will be used to match
  // with an action's platform for selection
  repeated ExecutionPolicy execution_policies = 22;
  
  bool error_operation_remaining_resources = 26;

  // user principal name for executions
  string exec_owner = 29;

  // a limit on time (in seconds) for input fetch stage to fetch inputs
  int32 input_fetch_deadline = 30;
}

message TreeIteratorToken {
  repeated build.bazel.remote.execution.v2.Digest directories = 1;
}

message OperationIteratorToken {
  string operation_name = 1;
}

message BlobWriteKey {
  build.bazel.remote.execution.v2.Digest digest = 1;

  string identifier = 2;
}

message OperationTimesBetweenStages {
  google.protobuf.Duration queued_to_match = 1;

  google.protobuf.Duration match_to_input_fetch_start = 2;

  google.protobuf.Duration input_fetch_start_to_complete = 3;

  google.protobuf.Duration input_fetch_complete_to_execution_start = 4;

  google.protobuf.Duration execution_start_to_complete = 5;

  google.protobuf.Duration execution_complete_to_output_upload_start = 6;

  google.protobuf.Duration output_upload_start_to_complete = 7;

  google.protobuf.Duration period = 8;

  int32 operation_count = 9;
}

message StageInformation {
  // name of the stage this message represent, i.e. InputFetchStage
  string name = 1;

  // number of slots configured for this stage
  int32 slots_configured = 2;

  // number of slots used for this stage
  int32 slots_used = 3;
}

message WorkerProfileMessage {
  // number of Entry in CAS
  int64 cas_entry_count = 1;

  // current size of the CAS as sum of entries
  int64 cas_size = 12;

  // configured maximum size of the CAS
  int64 cas_max_size = 13;

  // configured maximum entry size of the CAS
  int64 cas_max_entry_size = 14;

  // number of unreferenced Entry in CAS
  int64 cas_unreferenced_entry_count = 11;

  // number of DirectoryEntry in CAS
  int64 cas_directory_entry_count = 2;

  // number of evicted Entries since last profile request
  int32 cas_evicted_entry_count = 5;

  // the total size of evicted Entries since last profile request
  int64 cas_evicted_entry_size = 6;

  // used for removed fields representing composed used/configured slots
  reserved 7 to 8;

  repeated StageInformation stages = 9;

  repeated OperationTimesBetweenStages times = 10;
}

message WorkerProfileRequest {
}

message WorkerListRequest {
}

message WorkerListMessage {
  repeated string workers = 1;
}

service WorkerProfile {
  rpc GetWorkerProfile(WorkerProfileRequest) returns (WorkerProfileMessage) {}

  rpc GetWorkerList(WorkerListRequest) returns (WorkerListMessage) {}
}

message PrepareWorkerForGracefulShutDownRequest{
  string instance_name = 1;

  string worker_name = 2;
}

message PrepareWorkerForGracefulShutDownRequestResults{
}

service ShutDownWorker {
  rpc PrepareWorkerForGracefulShutdown(PrepareWorkerForGracefulShutDownRequest) returns (PrepareWorkerForGracefulShutDownRequestResults) {}
}

